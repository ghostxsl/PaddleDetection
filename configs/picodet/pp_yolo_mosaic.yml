_BASE_: [
  '../datasets/coco_detection.yml',
  '../runtime.yml',
  # '_base_/picodet_esnet.yml',
  # '_base_/optimizer_300e.yml',
  # '_base_/picodet_640_reader.yml',
]

weights: output/pp_yolo_mosaic/model_final
find_unused_parameters: True
use_ema: true
snapshot_epoch: 2
convert_sync_bn: true
ema_decay: 0.9998


architecture: PicoDet
# pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_vd_ssld_pretrained.pdparams
pretrain_weights: http://10.255.134.13:8091/cspdarknet53.pdparams

# wget http://10.255.134.13:8091/cspdarknet53.pdparams

PicoDet:
#   backbone: CSPDarkNet53
#   neck: CSPPAN
  backbone: CSPDarkNet
  neck: CustomPAN
  head: PicoHead

# CSPDarkNet53:
#   num_stages: 3
#   pretrained: '/paddle/repos/CSPDarkNet53_pretrained.pdparams'
# #   use_global_stats: true
# #   freeze_at: 1


CSPDarkNet:
  layers: 53
  return_idx: [2, 3, 4]


CustomPAN:
  block_per_stage: 1
  layer_per_block: 2
  act: 'leaky'
  block_func: 'CSPFusionBlock'
  block_size: 3
  keep_prob: 0.9
  spp: true


# CSPPAN:
#   out_channels: 512
#   use_depthwise: false
#   num_csp_blocks: 1
#   num_features: 4
#   kernel_size: 3
#   add_identity: true
#   expand_ratio: 0.5
#   t_kernel_size: 1


PicoHead:
#   conv_feat:
#     name: PicoFeatL
#     feat_in: 512
#     feat_out: 512
#     num_convs: 1
#     num_fpn_stride: 4
#     norm_type: bn
#     share_cls_reg: true
#     kernel_size: 3

  conv_feat:
    name: PicoFeatX
    feat_in: [256, 512, 1024]
    feat_out: 256
    num_convs: 0
    num_fpn_stride: 3
    norm_type: bn
    share_cls_reg: true
    kernel_size: 1
    # act: 'mish'

  fpn_stride: [8, 16, 32]
  feat_in_chan: [256, 512, 1024]
  prior_prob: 0.01
  reg_max: 12
  cell_offset: 0.5
  loss_class:
    name: VarifocalLoss
    use_sigmoid: True
    iou_weighted: True
    loss_weight: 1.0
  loss_dfl:
    name: DistributionFocalLoss
    loss_weight: 0.25
  loss_bbox:
    name: GIoULoss
    loss_weight: 2.0
  assigner:
    name: SimOTAAssignerX
    candidate_topk: 10
    iou_weight: 6 # 5
  nms:
    name: MultiClassNMS
    nms_top_k: 1000
    keep_top_k: 100
    score_threshold: 0.025
    nms_threshold: 0.6


worker_num: 8
TrainReader:
  sample_transforms:

  - Decode: {}
  # - RandomCrop: {}
  - RandomDistort: {}
  - RandomFlip: {prob: 0.5}

  - RandomResize: {target_size: [640], random_interp: True, keep_ratio: True}
  - Mosaic: {target_size: 640, mosaic_border: [-320, -320]} #  # x y w h
  - RandomPerspective: {debug: false, degree: 0, translate: 0.1, scale: 0.4, shear: 0.0, perspective: 0.0, border: [-320, -320]} # x y w h

  batch_transforms:
  - BatchRandomResize: {target_size: [416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}

  mosaic_epoch: 10000
  batch_size: 8
  shuffle: true
  drop_last: true
  collate_batch: false


EvalReader:
  sample_transforms:
  - Decode: {}
  # - Resize: {interp: 2, target_size: [640, 640], keep_ratio: False}
  - LetterBox: {debug: false, target_size: 640, rect: false, auto: false, augment: false}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 8
  shuffle: false


# epoch: 180
# LearningRate:
#   base_lr: 0.01
#   schedulers:
#   - !CosineDecay
#     max_epochs: 200
#   - !LinearWarmup
#     start_factor: 0.1
#     steps: 1000
# OptimizerBuilder:
#   optimizer:
#     momentum: 0.9
#     type: Momentum
#   regularizer:
#     factor: 0.0005
#     type: L2



epoch: 180
LearningRate:
  base_lr: 0.01
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones:
    - 120
  - !LinearWarmup
    start_factor: 0.1
    steps: 1000
OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0005
    type: L2



# epoch: 180

# LearningRate:
#   base_lr: 0.01
#   schedulers:
#     - !OneCycle
#       max_epochs: 180
#       use_warmup: True
#     - !LinearWarmup
#       start_factor: 0.1
#       steps: 1000 # 3 epochs, for minicoco 1.5 epochs # 3664

# OptimizerBuilder:
#   optimizer:
#     type: 'Momentum'
#     momentum: 0.9 # 0.937
#     use_nesterov: True
